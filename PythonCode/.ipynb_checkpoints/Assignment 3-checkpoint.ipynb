{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../datasets/Basketball/'\n",
    "result_dataset_path = './intermediate_datafiles/Basketball/'\n",
    "\n",
    "# Import the relevant classes.\n",
    "\n",
    "from Chapter2.CreateDataset import CreateDataset\n",
    "from util.VisualizeDataset import VisualizeDataset\n",
    "from util import util\n",
    "import copy\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Chapter3.KalmanFilters import KalmanFilters\n",
    "from Chapter3.DataTransformation import PrincipalComponentAnalysis\n",
    "\n",
    "\n",
    "DataViz = VisualizeDataset()\n",
    "if not os.path.exists(result_dataset_path):\n",
    "    print('Creating result directory: ' + result_dataset_path)\n",
    "    os.makedirs(result_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 2: Initial exploration of the dataset.\n",
    "\n",
    "# Set a granularity (i.e. how big are our discrete time steps). We start very\n",
    "# coarse grained, namely one measurement per minute, and secondly use four measurements\n",
    "# per second\n",
    "\n",
    "granularities = [500, 250]\n",
    "datasets = []\n",
    "\n",
    "for milliseconds_per_instance in granularities:\n",
    "\n",
    "    # Create an initial dataset object with the base directory for our data and a granularity\n",
    "    DataSet = CreateDataset(dataset_path, milliseconds_per_instance)\n",
    "\n",
    "    # Add the selected measurements to it.\n",
    "\n",
    "    # We add the accelerometer data (continuous numerical measurements) of the phone and the smartwatch\n",
    "    # and aggregate the values per timestep by averaging the values/\n",
    "    DataSet.add_numerical_dataset('Accelerometer.csv', 'timestamps', ['x','y','z'], 'avg', 'acc_')\n",
    "   \n",
    "\n",
    "    DataSet.add_numerical_dataset('Gravity.csv', 'timestamps', ['x','y','z'], 'avg', 'grav_')\n",
    "    DataSet.add_numerical_dataset('Gyroscope.csv', 'timestamps', ['x','y','z'], 'avg', 'gyr_')\n",
    "    DataSet.add_numerical_dataset('Linear_Acceleration.csv', 'timestamps', ['x','y','z'], 'avg', 'lin_acc_')\n",
    "    DataSet.add_numerical_dataset('Magnetometer.csv', 'timestamps', ['x','y','z'], 'avg', 'mag_')\n",
    "  #  DataSet.add_numerical_dataset('Orientation.csv', 'timestamps', ['x','y','z'], 'avg', 'orie_')\n",
    "    DataSet.add_numerical_dataset('Pressure.csv', 'timestamps', ['value1','value2'], 'avg', 'press_')\n",
    "    DataSet.add_numerical_dataset('Rotation vector.csv', 'timestamps', ['xsin','ysin','zsin','cos'], 'avg', 'rot_vec_')\n",
    "    DataSet.add_numerical_dataset('Step_Counter.csv', 'timestamps', ['step'], 'avg', 'step_')\n",
    "    \n",
    "    \n",
    "    DataSet.add_event_dataset('labels.csv', 'label_start', 'label_end', 'label', 'binary')\n",
    "\n",
    "   \n",
    "    # Get the resulting pandas data table\n",
    "\n",
    "    dataset = DataSet.data_table\n",
    "\n",
    "    # Plot the data\n",
    "\n",
    "\n",
    "    # Boxplot\n",
    "    DataViz.plot_dataset_boxplot(dataset, ['acc_x','acc_y','acc_z'])\n",
    "\n",
    "    # Plot all data\n",
    "   # DataViz.plot_dataset(dataset, ['acc_', 'grav_','gyr_','lin_acc_','mag_', 'orie_','press_','rot_vec_','step_', 'label'], ['like', 'like','like'], ['line', 'line', 'line', 'line', 'line', 'line', 'points', 'points'])\n",
    "    DataViz.plot_dataset(dataset, ['acc_', 'grav_','gyr_','lin_acc_','mag_','press_','rot_vec_','step_', 'label'], ['like', 'like','like','like', 'like','like','like', 'like','like'], ['line', 'line', 'line', 'line', 'line', 'line','line', 'points', 'points'],'basketball.png')\n",
    "\n",
    "    # And print a summary of the dataset\n",
    "\n",
    "    util.print_statistics(dataset)\n",
    "    datasets.append(copy.deepcopy(dataset))\n",
    "\n",
    "# And print the table that has been included in the book\n",
    "\n",
    "util.print_latex_table_statistics_two_datasets(datasets[0], datasets[1])\n",
    "\n",
    "# Finally, store the last dataset we have generated (250 ms).\n",
    "dataset.to_csv(result_dataset_path + 'chapter2_result.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get values \n",
    "dataset2 = dataset.loc[~dataset['lin_acc_x'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.to_csv(result_dataset_path + 'chapter2_result_dataset2.csv')\n",
    "dataset2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataViz.plot_dataset(dataset2, ['acc_', 'grav_','gyr_','lin_acc_','mag_','press_','rot_vec_','step_', 'label'], ['like', 'like','like','like', 'like','like','like', 'like','like'], ['line', 'line', 'line', 'line', 'line', 'line','line', 'points', 'points'],'basketball.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset3 = pd.read_csv(result_dataset_path + 'chapter2_result_dataset2.csv', index_col=0)\n",
    "except IOError as e:\n",
    "    print('File not found, try to run previous crowdsignals scripts first!')\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3['acc_z'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = dataset3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, time in enumerate(dataset3['index']):\n",
    "    dataset3['index'][index] = dataset['index'][270 + index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3.to_csv(result_dataset_path + 'chapter2_result_dataset3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = dataset3.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1338 entries, 2018-06-22 08:49:01.702 to 2018-06-22 08:54:35.952\n",
      "Data columns (total 29 columns):\n",
      "acc_x             1338 non-null float64\n",
      "acc_y             1338 non-null float64\n",
      "acc_z             1338 non-null float64\n",
      "grav_x            1338 non-null float64\n",
      "grav_y            1338 non-null float64\n",
      "grav_z            1338 non-null float64\n",
      "gyr_x             1338 non-null float64\n",
      "gyr_y             1338 non-null float64\n",
      "gyr_z             1338 non-null float64\n",
      "lin_acc_x         1338 non-null float64\n",
      "lin_acc_y         1338 non-null float64\n",
      "lin_acc_z         1338 non-null float64\n",
      "mag_x             1338 non-null float64\n",
      "mag_y             1338 non-null float64\n",
      "mag_z             1338 non-null float64\n",
      "press_value1      1202 non-null float64\n",
      "press_value2      1202 non-null float64\n",
      "rot_vec_xsin      0 non-null float64\n",
      "rot_vec_ysin      0 non-null float64\n",
      "rot_vec_zsin      0 non-null float64\n",
      "rot_vec_cos       0 non-null float64\n",
      "step_step         411 non-null float64\n",
      "labelWalk         1338 non-null int64\n",
      "labelStand        1338 non-null int64\n",
      "labelJumpshot     1338 non-null int64\n",
      "labelLayup        1338 non-null int64\n",
      "labelFadeaway     1338 non-null int64\n",
      "labelRun          1338 non-null int64\n",
      "labelCrossover    1338 non-null int64\n",
      "dtypes: float64(22), int64(7)\n",
      "memory usage: 313.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset3 = pd.read_csv(result_dataset_path + 'chapter2_result_dataset3.csv', index_col=0)\n",
    "except IOError as e:\n",
    "    print('File not found, try to run previous crowdsignals scripts first!')\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zdujmic\\AppData\\Local\\Continuum\\Anaconda2\\envs\\ml4qs\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: to_datetime is deprecated. Use pd.to_datetime(...)\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc_x_kalman'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a6b9a83b848d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mdataset4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKalFilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_kalman_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mDataViz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_imputed_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'original'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kalman'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'acc_x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset4\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc_x_kalman'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mDataViz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'acc_x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'acc_x_kalman'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'exact'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'exact'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'line'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zdujmic\\AppData\\Local\\Continuum\\Anaconda2\\envs\\ml4qs\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2057\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zdujmic\\AppData\\Local\\Continuum\\Anaconda2\\envs\\ml4qs\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2064\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zdujmic\\AppData\\Local\\Continuum\\Anaconda2\\envs\\ml4qs\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1386\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zdujmic\\AppData\\Local\\Continuum\\Anaconda2\\envs\\ml4qs\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3542\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3543\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3544\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zdujmic\\AppData\\Local\\Continuum\\Anaconda2\\envs\\ml4qs\\lib\\site-packages\\pandas\\indexes\\base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2134\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2135\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2136\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4433)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4279)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13742)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\src\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:13696)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc_x_kalman'"
     ]
    }
   ],
   "source": [
    "# Let us try the Kalman filter to impute missing data\n",
    "\n",
    "\n",
    "selected_predictor_cols = [c for c in dataset3.columns if (not ('label' in c)) ]\n",
    "\n",
    "dataset3.index = dataset3.index.to_datetime()\n",
    "KalFilter = KalmanFilters()\n",
    "for col in selected_predictor_cols:\n",
    "    dataset4 = KalFilter.apply_kalman_filter(dataset3, col,True)\n",
    "    \n",
    "DataViz.plot_imputed_values(dataset4, ['original', 'kalman'], 'acc_x', dataset4['acc_x'])\n",
    "DataViz.plot_dataset(dataset4, ['acc_x', 'acc_x'], ['exact','exact'], ['line', 'line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_predictor_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Determine the PC's for all but our target columns (the labels and the heart rate)\n",
    "# We simplify by ignoring both, we could also ignore one first, and apply a PC to the remainder.\n",
    "selected_predictor_cols = [c for c in dataset4.columns if (not ('label' in c)) ]\n",
    "\n",
    "PCA = PrincipalComponentAnalysis()\n",
    "pc_values = PCA.determine_pc_explained_variance(dataset4, selected_predictor_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the variance explained.\n",
    "\n",
    "plot.plot(range(1, len(selected_predictor_cols)+1), pc_values, 'b-')\n",
    "plot.xlabel('principal component number')\n",
    "plot.ylabel('explained variance')\n",
    "plot.show(block=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We select 7 as the best number of PC's as this explains most of the variance\n",
    "\n",
    "n_pcs = 7\n",
    "\n",
    "dataset = PCA.apply_pca(copy.deepcopy(dataset4), selected_predictor_cols, n_pcs)\n",
    "\n",
    "#And we visualize the result of the PC's\n",
    "\n",
    "DataViz.plot_dataset(dataset4, ['pca_', 'label'], ['like', 'like'], ['line', 'points'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
