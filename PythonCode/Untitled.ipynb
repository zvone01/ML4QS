{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_path = '../datasets/ourdata/'\n",
    "dataset_crowdsignals_path = '../datasets/crowdsignals.io/csv-participant-one/'\n",
    "result_dataset_path = './intermediate_datafiles/'\n",
    "result_dataset_crowdsignals_path = './intermediate_datafiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the relevant classes.\n",
    "\n",
    "from Chapter2.CreateDataset import CreateDataset\n",
    "from util.VisualizeDataset import VisualizeDataset\n",
    "from util import util\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(result_dataset_path):\n",
    "    print('Creating result directory: ' + result_dataset_path)\n",
    "    os.makedirs(result_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "granularities = [100, 1000]\n",
    "datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for milliseconds_per_instance in granularities:\n",
    "\n",
    "    # Create an initial dataset object with the base directory for our data and a granularity\n",
    "    DataSet = CreateDataset(dataset_path, milliseconds_per_instance)\n",
    "\n",
    "    # Add the selected measurements to it.\n",
    "\n",
    "    # We add the accelerometer data (continuous numerical measurements) of the phone and the smartwatch\n",
    "    # and aggregate the values per timestep by averaging the values/\n",
    "    DataSet.add_numerical_dataset('accelerometer.csv', 'timestamps', ['x','y','z'], 'avg', 'acc_phone_')\n",
    "    #DataSet.add_numerical_dataset('accelerometer_smartwatch.csv', 'timestamps', ['x','y','z'], 'avg', 'acc_watch_')\n",
    "\n",
    "    # We add the gyroscope data (continuous numerical measurements) of the phone and the smartwatch\n",
    "    # and aggregate the values per timestep by averaging the values/\n",
    "    DataSet.add_numerical_dataset('gyroscope.csv', 'timestamps', ['x','y','z'], 'avg', 'gyr_phone_')\n",
    "\n",
    "\n",
    "    # We add the labels provided by the users. These are categorical events that might overlap. We add them\n",
    "    # as binary attributes (i.e. add a one to the attribute representing the specific value for the label if it\n",
    "    # occurs within an interval).\n",
    "    #DataSet.add_event_dataset('labels.csv', 'label_start', 'label_end', 'label', 'binary')\n",
    "\n",
    "    # We add the amount of light sensed by the phone (continuous numerical measurements) and aggregate by averaging again\n",
    "    DataSet.add_numerical_dataset('light.csv', 'timestamps', ['lux'], 'avg', 'light_phone_')\n",
    "\n",
    "    # We add the magnetometer data (continuous numerical measurements) of the phone and the smartwatch\n",
    "    # and aggregate the values per timestep by averaging the values\n",
    "    DataSet.add_numerical_dataset('magnetometer.csv', 'timestamps', ['x','y','z'], 'avg', 'mag_phone_')\n",
    "    \n",
    "\n",
    "    # Get the resulting pandas data table\n",
    "\n",
    "    dataset = DataSet.data_table\n",
    "\n",
    "    # Plot the data\n",
    "\n",
    "    DataViz = VisualizeDataset()\n",
    "\n",
    "    # Boxplot\n",
    "    DataViz.plot_dataset_boxplot(dataset, ['acc_phone_x','acc_phone_y','acc_phone_z'])\n",
    "\n",
    "    # Plot all data\n",
    "    DataViz.plot_dataset(dataset, ['acc_', 'gyr_', 'light_phone_lux', 'mag_'], ['like', 'like', 'like', 'like'], ['line', 'line', 'line', 'line'])\n",
    "\n",
    "    # And print a summary of the dataset\n",
    "\n",
    "    util.print_statistics(dataset)\n",
    "    datasets.append(copy.deepcopy(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# And print the table that has been included in the book\n",
    "\n",
    "util.print_latex_table_statistics_two_datasets(datasets[0], datasets[1])\n",
    "\n",
    "# Finally, store the last dataset we have generated (250 ms).\n",
    "dataset.to_csv(result_dataset_path + 'chapter2_result.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#crowdsignals data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(result_dataset_crowdsignals_path):\n",
    "    print('Creating result directory: ' + result_dataset_crowdsignals_path)\n",
    "    os.makedirs(result_dataset_crowdsignals_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "granularities_crowdsignals  = [60000, 30000]\n",
    "datasets_crowdsignals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for milliseconds_per_instance in granularities:\n",
    "\n",
    "    # Create an initial dataset object with the base directory for our data and a granularity\n",
    "    DataSet = CreateDataset(dataset_crowdsignals_path, milliseconds_per_instance)\n",
    "\n",
    "    # Add the selected measurements to it.\n",
    "\n",
    "    # We add the accelerometer data (continuous numerical measurements) of the phone and the smartwatch\n",
    "    # and aggregate the values per timestep by averaging the values/\n",
    "    DataSet.add_numerical_dataset('accelerometer_phone.csv', 'timestamps', ['x','y','z'], 'avg', 'acc_phone_')\n",
    "    DataSet.add_numerical_dataset('accelerometer_smartwatch.csv', 'timestamps', ['x','y','z'], 'avg', 'acc_watch_')\n",
    "\n",
    "    # We add the gyroscope data (continuous numerical measurements) of the phone and the smartwatch\n",
    "    # and aggregate the values per timestep by averaging the values/\n",
    "    DataSet.add_numerical_dataset('gyroscope_phone.csv', 'timestamps', ['x','y','z'], 'avg', 'gyr_phone_')\n",
    "    DataSet.add_numerical_dataset('gyroscope_smartwatch.csv', 'timestamps', ['x','y','z'], 'avg', 'gyr_watch_')\n",
    "\n",
    "    # We add the heart rate (continuous numerical measurements) and aggregate by averaging again\n",
    "    DataSet.add_numerical_dataset('heart_rate_smartwatch.csv', 'timestamps', ['rate'], 'avg', 'hr_watch_')\n",
    "\n",
    "    # We add the labels provided by the users. These are categorical events that might overlap. We add them\n",
    "    # as binary attributes (i.e. add a one to the attribute representing the specific value for the label if it\n",
    "    # occurs within an interval).\n",
    "    DataSet.add_event_dataset('labels.csv', 'label_start', 'label_end', 'label', 'binary')\n",
    "\n",
    "    # We add the amount of light sensed by the phone (continuous numerical measurements) and aggregate by averaging again\n",
    "    DataSet.add_numerical_dataset('light_phone.csv', 'timestamps', ['lux'], 'avg', 'light_phone_')\n",
    "\n",
    "    # We add the magnetometer data (continuous numerical measurements) of the phone and the smartwatch\n",
    "    # and aggregate the values per timestep by averaging the values\n",
    "    DataSet.add_numerical_dataset('magnetometer_phone.csv', 'timestamps', ['x','y','z'], 'avg', 'mag_phone_')\n",
    "    DataSet.add_numerical_dataset('magnetometer_smartwatch.csv', 'timestamps', ['x','y','z'], 'avg', 'mag_watch_')\n",
    "\n",
    "    # We add the pressure sensed by the phone (continuous numerical measurements) and aggregate by averaging again\n",
    "    DataSet.add_numerical_dataset('pressure_phone.csv', 'timestamps', ['pressure'], 'avg', 'press_phone_')\n",
    "\n",
    "    # Get the resulting pandas data table\n",
    "\n",
    "    dataset = DataSet.data_table\n",
    "\n",
    "    # Plot the data\n",
    "\n",
    "    DataViz = VisualizeDataset()\n",
    "\n",
    "    # Boxplot\n",
    "    DataViz.plot_dataset_boxplot(dataset, ['acc_phone_x','acc_phone_y','acc_phone_z','acc_watch_x','acc_watch_y','acc_watch_z'])\n",
    "\n",
    "    # Plot all data\n",
    "    DataViz.plot_dataset(dataset, ['acc_', 'gyr_', 'hr_watch_rate', 'light_phone_lux', 'mag_', 'press_phone_', 'label'], ['like', 'like', 'like', 'like', 'like', 'like', 'like','like'], ['line', 'line', 'line', 'line', 'line', 'line', 'points', 'points'])\n",
    "\n",
    "    # And print a summary of the dataset\n",
    "\n",
    "    util.print_statistics(datasets_crowdsignals)\n",
    "    datasets_crowdsignals.append(copy.deepcopy(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
